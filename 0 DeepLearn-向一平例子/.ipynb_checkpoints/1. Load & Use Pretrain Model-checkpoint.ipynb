{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ea421d-10f2-4350-950f-93da7f22936d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 加载预训练模型\n",
    "### 以BERT和pytorch为例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0427f-4f13-468d-9c53-be7280958176",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### STEP 1: 安装环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1541410-30ef-4731-9be9-11ea05776ba9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### STEP 2:加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f3fa3a-0277-46c1-a06f-13d1b08cb750",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 方式1：抱抱脸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df45e55-e2ea-4990-b002-b1e099e0a1b9",
   "metadata": {},
   "source": [
    "模型库网站：抱抱脸（https://huggingface.co/）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdeaa66-888a-4105-be2a-e8b78b9166a7",
   "metadata": {},
   "source": [
    "安装 transformers 库\n",
    "\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed7af8b-9355-4cba-9c66-4fb275716bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c5686c-7d53-4b3b-9408-1dab1e6e4367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'hfl/chinese-roberta-wwm-ext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d974c922-d03c-47d7-b152-47d6ed16f753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed56ea6b225460a81aa1be8f19b3cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c8dfb2a0304504b9a81bd11dd93340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/393M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2caa76ba-f04f-4419-932e-92904a975520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a531bad7a3542a4a40547acc7e8a4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/107k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf0d52301714e5d89de5eddb060a8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96db4018c9bb481081dc9a99ec190fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a0e1d652b74d0bb9995a308e0c442d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/19.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a05ae0b145b44e18d08ac093f240a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/263k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8007df-b669-4e3f-b6ba-f7a4c69edb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = '我爱北京天安门'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b553a03a-72b4-493a-a275-cb4f6be0d95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token = tokenizer.encode_plus(sentence, max_length=32, truncation=True, \n",
    "                             padding='max_length', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57edc61a-c7c7-4581-b565-6f7a4eac138a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769, 4263, 1266,  776, 1921, 2128, 7305,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d154cf2-7a4b-445c-a636-e7ec89193e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = bert_model(**token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4c507a1-6e92-4cd5-9548-27e21a3ac347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1984, -0.0425, -0.6142,  ..., -0.9323,  0.3155, -0.2973],\n",
       "         [ 0.1143, -0.7477,  0.4193,  ..., -0.6956,  0.8122, -0.2701],\n",
       "         [ 0.1416,  0.0406, -0.4642,  ..., -0.7397,  0.1720, -0.8096],\n",
       "         ...,\n",
       "         [ 0.0642, -0.5344, -0.2778,  ..., -0.3421, -0.2578, -0.3953],\n",
       "         [ 0.0682, -0.5556, -0.2710,  ..., -0.3925, -0.2251, -0.3928],\n",
       "         [-0.0267, -0.5765, -0.2854,  ..., -0.4312, -0.1159, -0.3824]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.9843,  0.8932,  0.9737,  0.8303, -0.0210,  0.3184, -0.4281,  0.5382,\n",
       "          0.6436, -0.9398,  0.9947,  0.9610, -0.8076, -0.6108,  0.8535, -0.9343,\n",
       "          0.7185,  0.2558,  0.1680, -0.2996,  0.9783, -0.9894, -0.8317, -0.1969,\n",
       "          0.4169,  0.5812,  0.6278,  0.5455, -0.9860,  0.9437,  0.9851,  0.9273,\n",
       "          0.3592, -0.9859, -0.9943, -0.1022,  0.0728,  0.9741,  0.2282, -0.9461,\n",
       "         -0.8905, -0.0872, -0.4932, -0.9508,  0.8982,  0.4874, -0.9912, -0.9721,\n",
       "         -0.1266,  0.9302, -0.1452, -0.9150,  0.8256, -0.2778,  0.0105,  0.9583,\n",
       "         -0.9442,  0.5721,  0.9877, -0.3592,  0.9790, -0.2677,  0.2812, -0.9880,\n",
       "          0.9753, -0.9824, -0.9828,  0.8907,  0.8700,  0.9946,  0.2430,  0.9483,\n",
       "          0.9885,  0.0846, -0.1192,  0.9625, -0.2625,  0.7844, -0.9972, -0.4286,\n",
       "          0.9936,  0.7046, -0.9836, -0.2893, -0.9676, -0.9610, -0.8771,  0.9662,\n",
       "         -0.4540,  0.4405,  0.7064, -0.9348, -0.9964,  0.9157, -0.8595, -0.3797,\n",
       "         -0.8259,  0.9218, -0.4365, -0.8697, -0.1447, -0.4568, -0.9716, -0.9904,\n",
       "          0.2642,  0.9668,  0.6554, -0.9362,  0.9878,  0.7055, -0.9959, -0.9488,\n",
       "         -0.9876,  0.6948, -0.7993,  0.9786, -0.4354,  0.6527,  0.7345, -0.9805,\n",
       "          0.9659, -0.9367, -0.9697, -0.4680,  0.9501,  0.9816,  0.9831, -0.8858,\n",
       "          0.9456,  0.9942,  0.5689,  0.7670, -0.9810,  0.9559,  0.9358, -0.9139,\n",
       "          0.0458, -0.4771,  0.9977,  0.9739,  0.6327,  0.0188,  0.9112, -0.9573,\n",
       "          0.9760, -0.9937,  0.9378, -0.9944, -0.9634,  0.9581,  0.2420,  0.9982,\n",
       "          0.6889,  0.9905, -0.9193, -0.9855, -0.6530,  0.2138,  0.9403, -0.9744,\n",
       "          0.8424, -0.0537, -0.2129,  0.9484, -0.9882,  0.9491, -0.9008,  0.9892,\n",
       "          0.8507, -0.8962, -0.8227, -0.9507,  0.0308, -0.9524, -0.8286,  0.9119,\n",
       "         -0.9439,  0.9835,  0.4752, -0.3859,  0.7415, -0.8370, -0.9448,  0.8759,\n",
       "         -0.6920,  0.8522,  0.2349,  0.1373,  0.5745, -0.7835, -0.9374,  0.9574,\n",
       "          0.8660, -0.6172,  0.9480,  0.6935, -0.6280, -0.6648, -0.9934, -0.9132,\n",
       "          0.9929, -0.7772, -0.9432, -0.7683, -0.9707,  0.5117, -0.4795, -0.7820,\n",
       "         -0.5295, -0.9797, -0.5354, -0.6052, -0.9448,  0.1054,  0.6894,  0.1197,\n",
       "         -0.9503,  0.2012,  0.6548,  0.7100,  0.6658, -0.7919, -0.8746, -0.0557,\n",
       "         -0.6947,  0.7805,  0.9918,  0.9875,  0.8354, -0.5561,  0.0748,  0.9756,\n",
       "          0.4962, -0.9965,  0.4118, -0.8188, -0.8734,  0.9940, -0.9772,  0.9585,\n",
       "          0.9928, -0.5720,  0.9973, -0.7359, -0.9755, -0.9701,  0.9964,  0.3289,\n",
       "          0.9891, -0.9352, -0.9172,  0.1843, -0.5505, -0.9898, -0.9845,  0.6026,\n",
       "          0.9669,  0.9801,  0.5042, -0.9151, -0.9317, -0.9463,  0.9917, -0.2215,\n",
       "          0.9701,  0.9246,  0.2636, -0.2058,  0.7291, -0.8155, -0.9547, -0.3822,\n",
       "         -0.9878, -0.7814, -0.9916,  0.7281, -0.8824, -0.9964,  0.8884,  0.9965,\n",
       "         -0.2423, -0.9877,  0.9833,  0.7574,  0.5597,  0.1857,  0.9498, -0.9985,\n",
       "          0.9923, -0.9849,  0.9247, -0.8887, -0.9371, -0.1600,  0.9601,  0.9731,\n",
       "         -0.7689,  0.0328, -0.9771, -0.9773,  0.3701,  0.9887, -0.5787,  0.1584,\n",
       "         -0.9257, -0.0438,  0.7120, -0.9295, -0.9867,  0.5496,  0.9826, -0.9124,\n",
       "          0.9965,  0.9818,  0.9989, -0.4961, -0.7601,  0.9588,  0.1564,  0.3563,\n",
       "         -0.8482,  0.6219,  0.9288,  0.1946, -0.0923, -0.9875,  0.9530, -0.6457,\n",
       "         -0.0478,  0.7773, -0.9123,  0.2610,  0.9301, -0.9512,  0.9495, -0.9558,\n",
       "         -0.3579,  0.6138,  0.9625,  0.8747,  0.2895, -0.7203,  0.9838, -0.9949,\n",
       "          0.8477, -0.9876,  0.9548, -0.3375, -0.3590, -0.9081, -0.9189,  0.9842,\n",
       "          0.8960,  0.8762,  0.9685, -0.7572,  0.9540, -0.0755,  0.3066,  0.8460,\n",
       "          0.5448,  0.9836, -0.9755, -0.4465, -0.2782, -0.9441, -0.6622, -0.9890,\n",
       "         -0.2656, -0.8468, -0.7953,  0.0844, -0.7037, -0.3491,  0.0908, -0.9291,\n",
       "         -0.1831,  0.2106,  0.7020,  0.6757,  0.8098, -0.9290, -0.7855, -0.9935,\n",
       "         -0.9205, -0.2415,  0.9738, -0.9935,  0.9600, -0.9920, -0.7932, -0.3714,\n",
       "         -0.8705, -0.1520, -0.0177, -0.9697,  0.9751,  0.9440,  0.9974,  0.9468,\n",
       "          0.9372, -0.3946, -0.8352, -0.9477, -0.9849, -0.9985, -0.9854, -0.0856,\n",
       "          0.6117, -0.9875, -0.5258,  0.7293,  0.9835,  0.9693, -0.9906, -0.4916,\n",
       "         -0.9903, -0.9211,  0.9846,  0.7696, -0.8786,  0.7330,  0.3248,  0.9770,\n",
       "         -0.1077,  0.3015,  0.3609,  0.3416,  0.8635, -0.9467,  0.3123,  0.9951,\n",
       "          0.7663, -0.9906, -0.4114,  0.3482, -0.9871, -0.6296,  0.8418,  0.9684,\n",
       "         -0.9943, -0.5077, -0.8505,  0.7455,  0.8310,  0.8718,  0.9563,  0.9032,\n",
       "          0.9815, -0.7855,  0.4358,  0.9416,  0.1677, -0.9312,  0.9671, -0.9577,\n",
       "          0.3280, -0.9724,  0.9340, -0.4707,  0.9806,  0.4454, -0.2283, -0.9594,\n",
       "         -0.9604,  0.9387,  0.9907, -0.1363, -0.8335, -0.9532, -0.9926, -0.9720,\n",
       "         -0.8193,  0.4366, -0.9225, -0.9375,  0.6746,  0.8243,  0.9977,  0.9857,\n",
       "          0.9868, -0.7165, -0.7170,  0.9654, -0.7343,  0.7520, -0.6207, -0.9862,\n",
       "         -0.9410, -0.9715,  0.9587,  0.4946,  0.1468, -0.6154,  0.6670,  0.3753,\n",
       "         -0.9833,  0.2325, -0.9236,  0.9771,  0.9970, -0.6482,  0.8861, -0.8429,\n",
       "         -0.0077,  0.8282,  0.9639,  0.9636, -0.9456, -0.1946, -0.5126,  0.7152,\n",
       "          0.7386,  0.8361, -0.9211, -0.6050,  0.9567, -0.5999,  0.8363, -0.4378,\n",
       "          0.1979,  0.9054,  0.9694,  0.4408,  0.8908, -0.3528,  0.5756,  0.9854,\n",
       "          0.4404,  0.3807, -0.0049, -0.8328,  0.0943,  0.8147,  0.8423,  0.2353,\n",
       "         -0.3676, -0.9703,  0.8120,  0.9138,  0.9981, -0.2258,  0.9758,  0.4382,\n",
       "          0.6821,  0.0477,  0.9389,  0.5407,  0.7707,  0.9880,  0.9868, -0.9773,\n",
       "         -0.9450, -0.9946,  0.9938,  0.8671, -0.0816, -0.9910,  0.9417, -0.4578,\n",
       "         -0.7350,  0.9624,  0.2147, -0.9969,  0.9024, -0.9394,  0.4175, -0.2343,\n",
       "          0.9153, -0.1801,  0.9827, -0.9611, -0.1068,  0.9953,  0.1798,  0.9622,\n",
       "          0.4940, -0.9969,  0.9395, -0.3057, -0.9731,  0.2889,  0.9829,  0.9824,\n",
       "          0.0727, -0.4322,  0.8846, -0.9310,  0.9820, -0.9901,  0.1588, -0.9454,\n",
       "          0.9816, -0.9250, -0.9894, -0.1963,  0.2867, -0.3983,  0.4536,  0.9936,\n",
       "         -0.2788, -0.8981, -0.4914,  0.7188, -0.8776, -0.9754,  0.5948, -0.9425,\n",
       "          0.3536, -0.8553, -0.3197, -0.8685, -0.9157,  0.9775, -0.7056, -0.9223,\n",
       "          0.9945,  0.0964, -0.9905,  0.3052, -0.7391, -0.3062,  0.2094,  0.4873,\n",
       "          0.0447, -0.9982,  0.8439,  0.9408, -0.9910, -0.3794, -0.6808, -0.8743,\n",
       "         -0.5709,  0.8558,  0.8062, -0.3767, -0.0227,  0.2767,  0.9184, -0.4265,\n",
       "          0.7789, -0.1514, -0.7449, -0.9090, -0.9249, -0.9740, -0.9593,  0.9918,\n",
       "          0.8772,  0.9855, -0.7037, -0.1422,  0.8901,  0.8789, -0.9949,  0.0430,\n",
       "          0.6384,  0.4631, -0.1621, -0.8830,  0.6078, -0.9877, -0.9420,  0.6767,\n",
       "          0.4707, -0.8834,  0.9788,  0.9233, -0.9421, -0.7200, -0.9874, -0.8000,\n",
       "          0.9826,  0.7873,  0.9805, -0.6817, -0.7229,  0.9252,  0.1384, -0.7599,\n",
       "         -0.9750, -0.9842, -0.9616,  0.7381, -0.9641, -0.9737,  0.9906,  0.9813,\n",
       "          0.5320, -0.9806, -0.5608,  0.9823,  0.9477,  0.9975,  0.6575,  0.9866,\n",
       "         -0.8578,  0.9328, -0.8173,  0.9924, -0.9842,  0.9896,  0.9896,  0.5549,\n",
       "          0.9461, -0.9795, -0.4003, -0.7871,  0.0836, -0.1580, -0.1858, -0.9660,\n",
       "         -0.8438,  0.8794, -0.9857,  0.9941, -0.5100, -0.5227,  0.8803,  0.0457,\n",
       "          0.7702,  0.9294, -0.9957,  0.0205,  0.8622,  0.7344,  0.9834,  0.8485,\n",
       "          0.8529, -0.7993, -0.9299, -0.0168, -0.8997, -0.1071, -0.8310,  0.9580,\n",
       "          0.9799, -0.9804,  0.1886, -0.1470,  0.8768,  0.8807,  0.9564, -0.6301,\n",
       "          0.5262,  0.5484,  0.9385, -0.9853,  0.8672, -0.9249,  0.2417,  0.9488,\n",
       "         -0.8821,  0.9400, -0.8961,  0.9821, -0.8816, -0.2316,  0.9769,  0.8928,\n",
       "         -0.8071,  0.9849,  0.5800, -0.8980, -0.9523, -0.8987, -0.8803, -0.2864]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ac37cb4-ca28-4a78-9673-c9178153d79a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1984, -0.0425, -0.6142,  ..., -0.9323,  0.3155, -0.2973],\n",
       "         [ 0.1143, -0.7477,  0.4193,  ..., -0.6956,  0.8122, -0.2701],\n",
       "         [ 0.1416,  0.0406, -0.4642,  ..., -0.7397,  0.1720, -0.8096],\n",
       "         ...,\n",
       "         [ 0.0642, -0.5344, -0.2778,  ..., -0.3421, -0.2578, -0.3953],\n",
       "         [ 0.0682, -0.5556, -0.2710,  ..., -0.3925, -0.2251, -0.3928],\n",
       "         [-0.0267, -0.5765, -0.2854,  ..., -0.4312, -0.1159, -0.3824]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b60e59c8-84b9-48c1-b970-8fc0fd4e7464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb4f7e-1fb6-4823-8167-ae1d75c87700",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 方式2：本地加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19de8fff-b215-4008-868b-f975419dc91a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = 'E:\\\\Visual Code Projects\\\\DL Starter\\\\RoBERTa Example\\\\models\\\\chinese-roberta-wwm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09058b94-1c5d-4829-925e-f2888fcc0362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:\\Visual Code Projects\\DL Starter\\RoBERTa Example\\models\\chinese-roberta-wwm were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "roberta = BertModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "558f33a7-095b-4989-9512-33275be205f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roberta_tokenizer = BertTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcd39a75-f197-422f-a2bf-01025f1d2fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token2 = roberta_tokenizer.encode_plus(sentence, max_length=32, truncation=True,\n",
    "                                      padding='max_length', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee63e912-366f-49ed-b7c7-2a2cc0a26049",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769, 4263, 1266,  776, 1921, 2128, 7305,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13631316-db71-44be-83d0-ad769c479fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = roberta(**token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61ab276e-eaba-4d90-8be2-2160a3037fd5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1984, -0.0425, -0.6142,  ..., -0.9323,  0.3155, -0.2973],\n",
       "         [ 0.1143, -0.7477,  0.4193,  ..., -0.6956,  0.8122, -0.2701],\n",
       "         [ 0.1416,  0.0406, -0.4642,  ..., -0.7397,  0.1720, -0.8096],\n",
       "         ...,\n",
       "         [ 0.0642, -0.5344, -0.2778,  ..., -0.3421, -0.2578, -0.3953],\n",
       "         [ 0.0682, -0.5556, -0.2710,  ..., -0.3925, -0.2251, -0.3928],\n",
       "         [-0.0267, -0.5765, -0.2854,  ..., -0.4312, -0.1159, -0.3824]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.9843,  0.8932,  0.9737,  0.8303, -0.0210,  0.3184, -0.4281,  0.5382,\n",
       "          0.6436, -0.9398,  0.9947,  0.9610, -0.8076, -0.6108,  0.8535, -0.9343,\n",
       "          0.7185,  0.2558,  0.1680, -0.2996,  0.9783, -0.9894, -0.8317, -0.1969,\n",
       "          0.4169,  0.5812,  0.6278,  0.5455, -0.9860,  0.9437,  0.9851,  0.9273,\n",
       "          0.3592, -0.9859, -0.9943, -0.1022,  0.0728,  0.9741,  0.2282, -0.9461,\n",
       "         -0.8905, -0.0872, -0.4932, -0.9508,  0.8982,  0.4874, -0.9912, -0.9721,\n",
       "         -0.1266,  0.9302, -0.1452, -0.9150,  0.8256, -0.2778,  0.0105,  0.9583,\n",
       "         -0.9442,  0.5721,  0.9877, -0.3592,  0.9790, -0.2677,  0.2812, -0.9880,\n",
       "          0.9753, -0.9824, -0.9828,  0.8907,  0.8700,  0.9946,  0.2430,  0.9483,\n",
       "          0.9885,  0.0846, -0.1192,  0.9625, -0.2625,  0.7844, -0.9972, -0.4286,\n",
       "          0.9936,  0.7046, -0.9836, -0.2893, -0.9676, -0.9610, -0.8771,  0.9662,\n",
       "         -0.4540,  0.4405,  0.7064, -0.9348, -0.9964,  0.9157, -0.8595, -0.3797,\n",
       "         -0.8259,  0.9218, -0.4365, -0.8697, -0.1447, -0.4568, -0.9716, -0.9904,\n",
       "          0.2642,  0.9668,  0.6554, -0.9362,  0.9878,  0.7055, -0.9959, -0.9488,\n",
       "         -0.9876,  0.6948, -0.7993,  0.9786, -0.4354,  0.6527,  0.7345, -0.9805,\n",
       "          0.9659, -0.9367, -0.9697, -0.4680,  0.9501,  0.9816,  0.9831, -0.8858,\n",
       "          0.9456,  0.9942,  0.5689,  0.7670, -0.9810,  0.9559,  0.9358, -0.9139,\n",
       "          0.0458, -0.4771,  0.9977,  0.9739,  0.6327,  0.0188,  0.9112, -0.9573,\n",
       "          0.9760, -0.9937,  0.9378, -0.9944, -0.9634,  0.9581,  0.2420,  0.9982,\n",
       "          0.6889,  0.9905, -0.9193, -0.9855, -0.6530,  0.2138,  0.9403, -0.9744,\n",
       "          0.8424, -0.0537, -0.2129,  0.9484, -0.9882,  0.9491, -0.9008,  0.9892,\n",
       "          0.8507, -0.8962, -0.8227, -0.9507,  0.0308, -0.9524, -0.8286,  0.9119,\n",
       "         -0.9439,  0.9835,  0.4752, -0.3859,  0.7415, -0.8370, -0.9448,  0.8759,\n",
       "         -0.6920,  0.8522,  0.2349,  0.1373,  0.5745, -0.7835, -0.9374,  0.9574,\n",
       "          0.8660, -0.6172,  0.9480,  0.6935, -0.6280, -0.6648, -0.9934, -0.9132,\n",
       "          0.9929, -0.7772, -0.9432, -0.7683, -0.9707,  0.5117, -0.4795, -0.7820,\n",
       "         -0.5295, -0.9797, -0.5354, -0.6052, -0.9448,  0.1054,  0.6894,  0.1197,\n",
       "         -0.9503,  0.2012,  0.6548,  0.7100,  0.6658, -0.7919, -0.8746, -0.0557,\n",
       "         -0.6947,  0.7805,  0.9918,  0.9875,  0.8354, -0.5561,  0.0748,  0.9756,\n",
       "          0.4962, -0.9965,  0.4118, -0.8188, -0.8734,  0.9940, -0.9772,  0.9585,\n",
       "          0.9928, -0.5720,  0.9973, -0.7359, -0.9755, -0.9701,  0.9964,  0.3289,\n",
       "          0.9891, -0.9352, -0.9172,  0.1843, -0.5505, -0.9898, -0.9845,  0.6026,\n",
       "          0.9669,  0.9801,  0.5042, -0.9151, -0.9317, -0.9463,  0.9917, -0.2215,\n",
       "          0.9701,  0.9246,  0.2636, -0.2058,  0.7291, -0.8155, -0.9547, -0.3822,\n",
       "         -0.9878, -0.7814, -0.9916,  0.7281, -0.8824, -0.9964,  0.8884,  0.9965,\n",
       "         -0.2423, -0.9877,  0.9833,  0.7574,  0.5597,  0.1857,  0.9498, -0.9985,\n",
       "          0.9923, -0.9849,  0.9247, -0.8887, -0.9371, -0.1600,  0.9601,  0.9731,\n",
       "         -0.7689,  0.0328, -0.9771, -0.9773,  0.3701,  0.9887, -0.5787,  0.1584,\n",
       "         -0.9257, -0.0438,  0.7120, -0.9295, -0.9867,  0.5496,  0.9826, -0.9124,\n",
       "          0.9965,  0.9818,  0.9989, -0.4961, -0.7601,  0.9588,  0.1564,  0.3563,\n",
       "         -0.8482,  0.6219,  0.9288,  0.1946, -0.0923, -0.9875,  0.9530, -0.6457,\n",
       "         -0.0478,  0.7773, -0.9123,  0.2610,  0.9301, -0.9512,  0.9495, -0.9558,\n",
       "         -0.3579,  0.6138,  0.9625,  0.8747,  0.2895, -0.7203,  0.9838, -0.9949,\n",
       "          0.8477, -0.9876,  0.9548, -0.3375, -0.3590, -0.9081, -0.9189,  0.9842,\n",
       "          0.8960,  0.8762,  0.9685, -0.7572,  0.9540, -0.0755,  0.3066,  0.8460,\n",
       "          0.5448,  0.9836, -0.9755, -0.4465, -0.2782, -0.9441, -0.6622, -0.9890,\n",
       "         -0.2656, -0.8468, -0.7953,  0.0844, -0.7037, -0.3491,  0.0908, -0.9291,\n",
       "         -0.1831,  0.2106,  0.7020,  0.6757,  0.8098, -0.9290, -0.7855, -0.9935,\n",
       "         -0.9205, -0.2415,  0.9738, -0.9935,  0.9600, -0.9920, -0.7932, -0.3714,\n",
       "         -0.8705, -0.1520, -0.0177, -0.9697,  0.9751,  0.9440,  0.9974,  0.9468,\n",
       "          0.9372, -0.3946, -0.8352, -0.9477, -0.9849, -0.9985, -0.9854, -0.0856,\n",
       "          0.6117, -0.9875, -0.5258,  0.7293,  0.9835,  0.9693, -0.9906, -0.4916,\n",
       "         -0.9903, -0.9211,  0.9846,  0.7696, -0.8786,  0.7330,  0.3248,  0.9770,\n",
       "         -0.1077,  0.3015,  0.3609,  0.3416,  0.8635, -0.9467,  0.3123,  0.9951,\n",
       "          0.7663, -0.9906, -0.4114,  0.3482, -0.9871, -0.6296,  0.8418,  0.9684,\n",
       "         -0.9943, -0.5077, -0.8505,  0.7455,  0.8310,  0.8718,  0.9563,  0.9032,\n",
       "          0.9815, -0.7855,  0.4358,  0.9416,  0.1677, -0.9312,  0.9671, -0.9577,\n",
       "          0.3280, -0.9724,  0.9340, -0.4707,  0.9806,  0.4454, -0.2283, -0.9594,\n",
       "         -0.9604,  0.9387,  0.9907, -0.1363, -0.8335, -0.9532, -0.9926, -0.9720,\n",
       "         -0.8193,  0.4366, -0.9225, -0.9375,  0.6746,  0.8243,  0.9977,  0.9857,\n",
       "          0.9868, -0.7165, -0.7170,  0.9654, -0.7343,  0.7520, -0.6207, -0.9862,\n",
       "         -0.9410, -0.9715,  0.9587,  0.4946,  0.1468, -0.6154,  0.6670,  0.3753,\n",
       "         -0.9833,  0.2325, -0.9236,  0.9771,  0.9970, -0.6482,  0.8861, -0.8429,\n",
       "         -0.0077,  0.8282,  0.9639,  0.9636, -0.9456, -0.1946, -0.5126,  0.7152,\n",
       "          0.7386,  0.8361, -0.9211, -0.6050,  0.9567, -0.5999,  0.8363, -0.4378,\n",
       "          0.1979,  0.9054,  0.9694,  0.4408,  0.8908, -0.3528,  0.5756,  0.9854,\n",
       "          0.4404,  0.3807, -0.0049, -0.8328,  0.0943,  0.8147,  0.8423,  0.2353,\n",
       "         -0.3676, -0.9703,  0.8120,  0.9138,  0.9981, -0.2258,  0.9758,  0.4382,\n",
       "          0.6821,  0.0477,  0.9389,  0.5407,  0.7707,  0.9880,  0.9868, -0.9773,\n",
       "         -0.9450, -0.9946,  0.9938,  0.8671, -0.0816, -0.9910,  0.9417, -0.4578,\n",
       "         -0.7350,  0.9624,  0.2147, -0.9969,  0.9024, -0.9394,  0.4175, -0.2343,\n",
       "          0.9153, -0.1801,  0.9827, -0.9611, -0.1068,  0.9953,  0.1798,  0.9622,\n",
       "          0.4940, -0.9969,  0.9395, -0.3057, -0.9731,  0.2889,  0.9829,  0.9824,\n",
       "          0.0727, -0.4322,  0.8846, -0.9310,  0.9820, -0.9901,  0.1588, -0.9454,\n",
       "          0.9816, -0.9250, -0.9894, -0.1963,  0.2867, -0.3983,  0.4536,  0.9936,\n",
       "         -0.2788, -0.8981, -0.4914,  0.7188, -0.8776, -0.9754,  0.5948, -0.9425,\n",
       "          0.3536, -0.8553, -0.3197, -0.8685, -0.9157,  0.9775, -0.7056, -0.9223,\n",
       "          0.9945,  0.0964, -0.9905,  0.3052, -0.7391, -0.3062,  0.2094,  0.4873,\n",
       "          0.0447, -0.9982,  0.8439,  0.9408, -0.9910, -0.3794, -0.6808, -0.8743,\n",
       "         -0.5709,  0.8558,  0.8062, -0.3767, -0.0227,  0.2767,  0.9184, -0.4265,\n",
       "          0.7789, -0.1514, -0.7449, -0.9090, -0.9249, -0.9740, -0.9593,  0.9918,\n",
       "          0.8772,  0.9855, -0.7037, -0.1422,  0.8901,  0.8789, -0.9949,  0.0430,\n",
       "          0.6384,  0.4631, -0.1621, -0.8830,  0.6078, -0.9877, -0.9420,  0.6767,\n",
       "          0.4707, -0.8834,  0.9788,  0.9233, -0.9421, -0.7200, -0.9874, -0.8000,\n",
       "          0.9826,  0.7873,  0.9805, -0.6817, -0.7229,  0.9252,  0.1384, -0.7599,\n",
       "         -0.9750, -0.9842, -0.9616,  0.7381, -0.9641, -0.9737,  0.9906,  0.9813,\n",
       "          0.5320, -0.9806, -0.5608,  0.9823,  0.9477,  0.9975,  0.6575,  0.9866,\n",
       "         -0.8578,  0.9328, -0.8173,  0.9924, -0.9842,  0.9896,  0.9896,  0.5549,\n",
       "          0.9461, -0.9795, -0.4003, -0.7871,  0.0836, -0.1580, -0.1858, -0.9660,\n",
       "         -0.8438,  0.8794, -0.9857,  0.9941, -0.5100, -0.5227,  0.8803,  0.0457,\n",
       "          0.7702,  0.9294, -0.9957,  0.0205,  0.8622,  0.7344,  0.9834,  0.8485,\n",
       "          0.8529, -0.7993, -0.9299, -0.0168, -0.8997, -0.1071, -0.8310,  0.9580,\n",
       "          0.9799, -0.9804,  0.1886, -0.1470,  0.8768,  0.8807,  0.9564, -0.6301,\n",
       "          0.5262,  0.5484,  0.9385, -0.9853,  0.8672, -0.9249,  0.2417,  0.9488,\n",
       "         -0.8821,  0.9400, -0.8961,  0.9821, -0.8816, -0.2316,  0.9769,  0.8928,\n",
       "         -0.8071,  0.9849,  0.5800, -0.8980, -0.9523, -0.8987, -0.8803, -0.2864]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47d5c50f-be26-41b2-844b-b7db7420fc98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1984, -0.0425, -0.6142,  ..., -0.9323,  0.3155, -0.2973],\n",
       "         [ 0.1143, -0.7477,  0.4193,  ..., -0.6956,  0.8122, -0.2701],\n",
       "         [ 0.1416,  0.0406, -0.4642,  ..., -0.7397,  0.1720, -0.8096],\n",
       "         ...,\n",
       "         [ 0.0642, -0.5344, -0.2778,  ..., -0.3421, -0.2578, -0.3953],\n",
       "         [ 0.0682, -0.5556, -0.2710,  ..., -0.3925, -0.2251, -0.3928],\n",
       "         [-0.0267, -0.5765, -0.2854,  ..., -0.4312, -0.1159, -0.3824]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9471d00c-4492-40a7-b681-c7213c41595a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69f2cc-c549-4bb4-abd6-5f814d660366",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgs",
   "language": "python",
   "name": "mgs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
